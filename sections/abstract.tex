\begin{abstract}

    This work provides a comprehensive approach to address fairness and bias mitigation in the design and development of data-driven methods. A central focus is the proposal and implementation of an innovative \emph{Fair-by-Design} workflow, integrating various strategies for bias mitigation within data, algorithms, and decision-making processes.
    
    The study adopts a broad perspective on diverse datasets, aiming to establish equitable and unbiased applications of data-driven algorithms across various domains.
    
    The primary objective is to ensure the general, equitable, and unbiased application of data-driven algorithms.
    
    The methodology systematically evaluates multiple bias mitigation strategies, with a critical emphasis on comparing their impact on the predictive accuracy of the algorithms.
    
    This approach yields practical insights into the trade-offs between fairness and accuracy, illustrating how different approaches can lead to varying accuracy scores on the same dataset and with the same models.
    
    The findings provide valuable insights into the trade-offs between fairness and accuracy when developing data-driven methods.
    
    This thesis significantly contributes to the ongoing discourse on fairness in machine learning and data-driven decision-making. The results offer guidance to stakeholders across sectors, aiding them in making informed decisions about algorithm deployment to promote fairness and minimize bias.

\end{abstract}
    