\documentclass{article}
\usepackage{amsmath}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{algorithm}
\usepackage[utf8]{inputenc}
\usepackage{algpseudocode}
\usepackage{tabularx}
\usepackage{graphicx}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}

\section{Fairness through unawareness with proxy detection}

\subsection{Algorithm description}
In the following we are going to describe the algorithm presented here in its two different versions: the one that comes out using the \textbf{apriori} algorithm and the one that comes out using \textbf{variables only} to perform proxy detection. \\

Let's consider a dataset \( D \) belonging to \( \mathbb{R}^{n \times m} \) with \( k \) protected variables. \\

We define \textit{fairness\_evaluation} as follows:
\[
\text{fairness\_evaluation}(v_i, Y) = \lambda(v_i, Y) \quad \forall i \in [1, k]
\]

where:
\begin{align*}
v\_i & : \text{ith attribute belonging to the protected variables}, \\
Y & : \text{output column}.
\end{align*}

The fairness function \( \lambda \) evaluates the relationship between a protected attribute \( v_i \) and the output \( Y \), producing a value that represents the level of fairness for that protected attribute. \\

We define \textit{dataset\_fair} as follows: a dataset \( D \) is considered fair if for every value \( v \) belonging to \textit{fairness\_evaluation}, the following condition holds:
\[ 0.8  < v < 1.25 \] \\

Before going on it's important to remark that we delve into the critical task of identifying proxy variables within the dataset. We specifically concentrate on leveraging fairness metrics, normal variables, and protected variables to determine proxies. Proxy variables are indirect indicators or correlates that may indirectly affect sensitive attributes, potentially introducing bias in our dataset. By examining the relationships between these variables and evaluating them based on fairness metrics, we aim to discern which variables exhibit significant associations with the sensitive attributes, leading to their identification as potential proxies. We focus on utilizing fairness metrics to ensure a comprehensive evaluation that considers both the fairness and equity aspects of the dataset, with the ultimate goal of achieving a more equitable and unbiased data representation. \\

So, considering the relevance of proxy detection in this algorithm it's important to move on and define the two approaches to detect these variables. \\

\subsubsection{Proxy detection via attributes only}
Let's consider the set \( A \), represented as the set of all variables in the dataset excluding the protected variables, and the set \( B \), representing the protected variables.

We define \textit{proxy\_detection} as follows: for every variable \( \text{var} \) belonging to \( A \) and for every protected variable \( \text{var\_protected} \) belonging to \( B \), the variable is a proxy if the fairness metric \( \lambda(\text{var}, \text{var\_protected}) \) satisfies the condition:

\[
\lambda(\text{var}, \text{var\_protected}) <= 0.8 \quad \text{or} \quad \lambda(\text{var}, \text{var\_protected}) => 1.25
\]

In other words, a variable \( \text{var} \) is considered a proxy if the fairness measure \( \lambda \) between \( \text{var} \) and a protected variable \( \text{var\_protected} \) falls outside the acceptable range ]0.8, 1.25[. \\

\subsubsection{Proxy detection via apriori}
It's important to give a brief background of the Association Rule Mining, the family algorithm \textbf{apriori} belongs to.

\begin{enumerate}
    \item \textbf{Association rule mining}: this is a data mining technique used to discover interesting relationships and patterns within large volumes of data. The goal is to identify associations and correlations among various elements present in the data.

    \item \textbf{Apriori algorithm}: Suppose we have a set of transactions $T$, each containing a set of items. Let's define:

\begin{itemize}
  \item $I$: the set of all distinct items in the data.
  \item $D$: the set of transactions, each represented by a set of items.
  \item $F_k$: the set of frequent itemsets of length $k$.
\end{itemize}

The Apriori algorithm operates in iterations, generating $F_k$ from $F_{k-1}$.

\textbf{Step 1:} Initialization:
$$F_1 = \{ \text{frequent item } i, i \in I \}$$

\textbf{Step 2:} Candidate itemset generation:
$$C_k = \{ \text{set } c \text{ of items such that } c \subseteq F_{k-1} \}$$

\textbf{Step 3:} Database scan:
$$\text{For each transaction } t \text{ in } D, \text{ increment the support count of each candidate in } C_k \text{ contained in } t.$$

\textbf{Step 4:} Selection of frequent itemsets:
$$F_k = \{ c \in C_k \text{ such that the support of } c \geq \text{ specified threshold} \}$$

\item \textbf{Row Selection with a Confidence Level}: 
suppose we have obtained association rules using the Apriori algorithm. Each rule $R$ is in the form $A \rightarrow B$, where $A$ is the antecedent and $B$ is the consequent. The confidence of $R$ is defined as:

\[
\text{Confidence}(R) = \frac{\text{Support}(A \cup B)}{\text{Support}(A)}
\]

To select rows with a certain confidence level, we consider a confidence threshold $C_{\text{min}}$. If the confidence of a rule $R$ exceeds this threshold, the rule is accepted.

Formally, a rule $A \rightarrow B$ is accepted if:

\[
\text{Confidence}(A \rightarrow B) \geq C_{\text{min}}
\]
In our scenario
\[
C_{\text{min}}
\]
is equal to 0.8. \\

Furthermore, in order to have a proper rows selection, we are particularly interested in privacy and data protection. We only want to consider rules where the consequent ($B$) contains at least one item representing a sensitive attribute or a variable that needs to be protected.

The consequent filtering process involves evaluating each rule to ensure it meets this criteria. If the consequent of a rule does not contain any sensitive attributes, we discard that rule from our final selection. \\

Formally, a rule $A \rightarrow B$ is considered if:

\[
\exists b \in B : b \in S
\]

If this condition is not met, the rule is discarded from our final selection.
\end{enumerate}
\\
After this brief introduction of the concepts used to apply this algorithm we present our approach to detect proxy variables. \\
We define \textit{proxy\_detection} as follows: for each antecedent \( A_i \) belonging to the antecedent list \( \mathcal{A} \), for each consequent \( C_j \) belonging to the consequent list \( \mathcal{C} \), and for each protected variable \( V_k \) belonging to the protected variable list \( \mathcal{V} \), \( A_i \) is a proxy if the fairness metric \( \lambda(A_i, C_j) \) is such that:

\[\lambda(A_i, C_j) <= 0.8 \quad \text{or} \quad \lambda(A_i, C_j) >= 1.25\]

In other words, an antecedent \( A_i \) is considered a proxy if the fairness measure \( \lambda \) between \( A_i \) and a consequent \( C_j \) is outside the acceptable range ]0.8, 1.25[.
\\
\\
There are two other fucnctions that needs to be defined in order to complete our algorithm.
\\
\\
Considering the dataset \( D \) belonging to \( \mathbb{R}^{n \times m} \) and \( k \) as the number of identified proxy variables, we define the function \( \text{proxy\_free\_dataset} \) as follows:

\[
\text{\textbf{proxy\_free\_dataset}}: D \times \mathbb{R}^{k \times 1} \rightarrow \mathbb{R}^{n \times (m - k)}
\]

where \( j = m - k \) and \( \text{proxy\_free\_dataset}(D) \) yields a dataset \( \mathbb{R}^{n \times j} \) devoid of the proxy variables, ensuring the removal of any potential indirect indicators that may influence sensitive attributes. \\
\\
Considering the dataset \( D \) belonging to \( \mathbb{R}^{n \times j} \) where j are the columns obtained after the proxy removals and \( k \) as the number of identified protected variables, we define the function \( \text{protected\_attributes\_free\_dataset} \) as follows:

\[
\text{\textbf{protected\_attributes\_free\_dataset}}: D \times \mathbb{R}^{k \times 1} \rightarrow \mathbb{R}^{n \times (j - k)}
\]

where \( p = j - k \) and \( \text{protected\_attributes\_free\_dataset}(D) \) yields a dataset \( \mathbb{R}^{n \times p} \) devoid of the protected variables, ensuring the removal of any potential indirect indicators that may influence sensitive attributes.

\subsection{Pseudocode}
Here's the pseudocode of the \emph{Fairness through unawareness with proxy detection}:
\begin{algorithm}[H]
    \KwData{dataset}
    \KwResult{fair dataset}
    \While{\textbf{not} \textit{dataset\_fair(dataset)} \textbf{or} \textit{protected\_attributes} \textbf{in} \textit{dataset}}{
        proxies = \textit{proxy\_detection(dataset)}\;
        \If{proxies \textbf{is empty}}{
            dataset = \textit{protected\_attributes\_free\_dataset(dataset)}\;
        }
        \Else{
            dataset = \textit{proxy\_free\_dataset(dataset)}\;
        }
    }
    \KwRet{dataset}
\end{algorithm}

\subsubsection{dataset\textunderscore fair pseudocode}
Here's the pseudocode that establish if the dataset is either \emph{Fair} or not
\begin{algorithm}[H]
    \KwData{dataset, protected\_attribute}
    \KwResult{Boolean value indicating fairness}
    \If{\textit{fairness\_evaluation(dataset, protected\_attribute)} \textbf{is empty}}{
        \KwRet{\textbf{True}}\;
    }
    \KwRet{\textbf{False}}
\end{algorithm}

\subsubsection{fairness\textunderscore evaluation pseudocode}
Here's the pseudocode to perform the fairness evaluation, given a specific \emph{fairness metric}
\begin{algorithm}[H]
    \KwData{dataset, output\_column, protected\_attributes}
    \KwResult{List of attributes failing fairness evaluation}
    fairness\_evaluation\_list $\gets$ empty list\;
    output $\gets$ dataset[output\_column]\;
    \For{attribute \textbf{in} protected\_attributes}{
        \If{\textit{metric(attribute, output)} $\leq$ 0.8 \textbf{or} \textit{metric(attribute, output)} $\geq$ 1.25}{
            \textit{fairness\_evaluation\_list.append(attribute)}\;
        }
    }
    \KwRet{fairness\_evaluation\_list}
\end{algorithm}

\subsubsection{protected\textunderscore attributes\textunderscore free\textunderscore dataset pseudocode}
Here's the pseudocode to remove protected attributes from the dataset

\begin{algorithm}[H]
    \KwData{dataset, protected\_attributes}
    \KwResult{Dataset with protected attributes removed}
    \For{attribute \textbf{in} protected\_attributes}{
        \textit{dataset.remove(attribute)}\;
    }
    \KwRet{dataset}
\end{algorithm}

\subsubsection{proxy\textunderscore free\textunderscore dataset pdeudocode}
Here's the pseudocode to remove proxy attributes from the dataset
\begin{algorithm}[H]
    \KwData{dataset, proxy\_list}
    \KwResult{Dataset with proxies removed}
    \For{proxy \textbf{in} proxy\_list}{
        \textit{dataset.remove(proxy)}\;
    }
    \KwRet{dataset}
\end{algorithm}

\subsubsection{proxy\textunderscore detection pseudocode}
Here's the pseudocode of proxy\textunderscore detection function. There are 2 scenarios that are presented here, the one in which the \emph{variables only}  approach is used and the one in which the \emph{apriori} approach is used

\begin{enumerate}
    \item \textbf{Variables only}: 
            
\begin{algorithm}[H]
    \KwData{protected\_attributes\_list, attributes}
    \KwResult{List of proxies}
    proxy\_list $\gets$ empty list\;
    \For{protected\_attribute \textbf{in} protected\_attributes\_list}{
        \For{attribute \textbf{in} attributes \textbf{and not in} protected\_attributes\_list \textbf{and not in} proxy\_list}{
            \If{\textit{metric(attribute, protected\_attribute)} $\leq$ 0.8 \textbf{or} \textit{metric(attribute, protected\_attribute)} $\geq$ 1.25}{
                \textit{proxy\_list.append(attribute)}\;
            }
        }
    }
    \KwRet{proxy\_list}
\end{algorithm}

    \item \textbf{Apriori}
    \begin{algorithm}[H]
    \KwData{apriori\_dataset}
    \KwResult{List of proxies}
    proxy\_list $\gets$ empty list\;
    \For{consequent \textbf{in} apriori\_dataset}{
        \For{antecedent \textbf{in} apriori\_dataset}{
            \If{\textit{metric(antecedent, consequent)} $\leq$ 0.8 \textbf{or} \textit{metric(antecedent, consequent)} $\geq$ 1.25}{
                \textit{proxy\_list.append(antecedent)}\;
            }
        }
    }
    \KwRet{proxy\_list}
\end{algorithm}
\end{enumerate}
