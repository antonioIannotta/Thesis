@article{mehrabi2021, 
	title={A Survey on Bias and Fairness in Machine Learning}, 
	volume={54}, 
	DOI={10.1145/3457607}, 
	number={115}, 
	journal={ACM Computing Survey}, 
	publisher={Association for Computing Machinery}, 
	author={Ninareh Mehrabi and Fred Morstatter and Nripsuta Saxena and Kristina Lerman and Aram Galstyan}, 
	year={2021}, 
	pages={1-35}}

@article{fairness_explained,
	title={Fairness definitions explained},
	DOI={10.1145/3194770.3194776},
	journal={FairWare '18: Proceedings of the International Workshop on Software Fairness},
	publisher={Association for Computing Machinery},
	author={Sahil Verma and Julia Rubin},
	year={2018},
	pages={1-7}
}

@article{https://doi.org/10.1002/widm.1356,
author = {Ntoutsi, Eirini and Fafalios, Pavlos and Gadiraju, Ujwal and Iosifidis, Vasileios and Nejdl, Wolfgang and Vidal, Maria-Esther and Ruggieri, Salvatore and Turini, Franco and Papadopoulos, Symeon and Krasanakis, Emmanouil and Kompatsiaris, Ioannis and Kinder-Kurlanda, Katharina and Wagner, Claudia and Karimi, Fariba and Fernandez, Miriam and Alani, Harith and Berendt, Bettina and Kruegel, Tina and Heinze, Christian and Broelemann, Klaus and Kasneci, Gjergji and Tiropanis, Thanassis and Staab, Steffen},
title = {Bias in data-driven artificial intelligence systems—An introductory survey},
journal = {WIREs Data Mining and Knowledge Discovery},
volume = {10},
number = {3},
pages = {e1356},
keywords = {fairness, fairness-aware AI, fairness-aware machine learning, interpretability, responsible AI},
doi = {https://doi.org/10.1002/widm.1356},
url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/widm.1356},
eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1356},
abstract = {Abstract Artificial Intelligence (AI)-based systems are widely employed nowadays to make decisions that have far-reaching impact on individuals and society. Their decisions might affect everyone, everywhere, and anytime, entailing concerns about potential human rights issues. Therefore, it is necessary to move beyond traditional AI algorithms optimized for predictive performance and embed ethical and legal principles in their design, training, and deployment to ensure social good while still benefiting from the huge potential of the AI technology. The goal of this survey is to provide a broad multidisciplinary overview of the area of bias in AI systems, focusing on technical challenges and solutions as well as to suggest new research directions towards approaches well-grounded in a legal frame. In this survey, we focus on data-driven AI, as a large part of AI is powered nowadays by (big) data and powerful machine learning algorithms. If otherwise not specified, we use the general term bias to describe problems related to the gathering or processing of data that might result in prejudiced decisions on the bases of demographic features such as race, sex, and so forth. This article is categorized under: Commercial, Legal, and Ethical Issues > Fairness in Data Mining Commercial, Legal, and Ethical Issues > Ethical Considerations Commercial, Legal, and Ethical Issues > Legal Issues},
year = {2020}
}

@inproceedings{10.1145/3308560.3317590,
author = {Roselli, Drew and Matthews, Jeanna and Talagala, Nisha},
title = {Managing Bias in AI},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3317590},
doi = {10.1145/3308560.3317590},
abstract = {Recent awareness of the impacts of bias in AI algorithms raises the risk for companies to deploy such algorithms, especially because the algorithms may not be explainable in the same way that non-AI algorithms are. Even with careful review of the algorithms and data sets, it may not be possible to delete all unwanted bias, particularly because AI systems learn from historical data, which encodes historical biases. In this paper, we propose a set of processes that companies can use to mitigate and manage three general classes of bias: those related to mapping the business intent into the AI implementation, those that arise due to the distribution of samples used for training, and those that are present in individual input samples. While there may be no simple or complete solution to this issue, best practices can be used to reduce the effects of bias on algorithmic outcomes.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {539–544},
numpages = {6},
keywords = {bias, Artificial intelligence, production monitoring},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{8746946,
  author={Sengupta, Eishvak and Garg, Dhruv and Choudhury, Tanupriya and Aggarwal, Archit},
  booktitle={2018 International Conference on System Modeling & Advancement in Research Trends (SMART)}, 
  title={Techniques to Elimenate Human Bias in Machine Learning}, 
  year={2018},
  volume={},
  number={},
  pages={226-230},
  doi={10.1109/SYSMART.2018.8746946}}

@inproceedings{10.1145/2908131.2908135,
author = {Baeza-Yates, Ricardo},
title = {Data and Algorithmic Bias in the Web},
year = {2016},
isbn = {9781450342087},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2908131.2908135},
doi = {10.1145/2908131.2908135},
abstract = {The Web is the largest public big data repository that humankind has created. In this overwhelming data ocean we need to be aware of the quality of data extracted from it. One important quality issue is data bias, which appears in different forms. These biases affect the (machine learning) algorithms that we design to improve the user experience. This problem is further exacerbated by biases that are added by these algorithms, especially in the context of recommendation and personalization systems. We give several examples, stressing the importance of the user context to avoid these biases.},
booktitle = {Proceedings of the 8th ACM Conference on Web Science},
pages = {1},
numpages = {1},
keywords = {data bias, algorithmic bias, noise, privacy, spam, diversity, novelty, redundancy},
location = {Hannover, Germany},
series = {WebSci '16}
}

@misc{barenstein2019propublicas,
      title={ProPublica's COMPAS Data Revisited}, 
      author={Matias Barenstein},
      year={2019},
      eprint={1906.04711},
      archivePrefix={arXiv},
      primaryClass={econ.GN}
}
